{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85d9a580",
   "metadata": {},
   "source": [
    "# AD2C : Test Bed\n",
    "\n",
    "This Jupter Notebook aims to Experiment with different Component of AD2C framework Like task, ESC, Callback and Loggers. This will also include advance experimental setup to test the trainied model. \n",
    "\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7295842a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cc6ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import hydra\n",
    "import wandb\n",
    "import sys\n",
    "import hydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Benchmarl & Project Imports\n",
    "import benchmarl.models\n",
    "from benchmarl.algorithms import *\n",
    "from benchmarl.environments import VmasTask\n",
    "from benchmarl.experiment import Experiment\n",
    "from benchmarl.hydra_config import (\n",
    "    load_algorithm_config_from_hydra,\n",
    "    load_experiment_config_from_hydra,\n",
    "    load_task_config_from_hydra,\n",
    "    load_model_config_from_hydra,\n",
    ")\n",
    "\n",
    "# Custom Callbacks\n",
    "from het_control.callback import *\n",
    "from het_control.environments.vmas import render_callback\n",
    "from het_control.models.het_control_mlp_empirical import HetControlMlpEmpiricalConfig\n",
    "from het_control.callbacks.esc_callback import ExtremumSeekingController\n",
    "from het_control.callbacks.sndESLogger import TrajectorySNDLoggerCallback\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import wandb\n",
    "from tensordict import TensorDict\n",
    "from typing import List\n",
    "from benchmarl.experiment.callback import Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25cc8cc",
   "metadata": {},
   "source": [
    "## SND Ploting Callback\n",
    "This allow us to display plots for the snd. from the eval run. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fd770da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_snd_visualizations(snd_matrix, n_agents, step_count):\n",
    "    \"\"\"\n",
    "    Generates 3 matplotlib figures (Heatmap, Bar, Graph) for a given SND matrix.\n",
    "    Returns a dictionary of wandb.Image objects.\n",
    "    Assumes snd_matrix is an N x N Symmetric Distance Matrix.\n",
    "    \"\"\"\n",
    "    plots = {}\n",
    "    \n",
    "    # Define pairs (Upper triangle only, since matrix is symmetric: 1-2 is same as 2-1)\n",
    "    pairs = [(i, j) for i in range(n_agents) for j in range(i + 1, n_agents)]\n",
    "    \n",
    "    # ==========================================\n",
    "    # 1. HEATMAP with Cell Values\n",
    "    # ==========================================\n",
    "    fig_heat, ax_heat = plt.subplots(figsize=(6, 5))\n",
    "    im = ax_heat.imshow(snd_matrix, cmap='viridis', interpolation='nearest', vmin=0, vmax=3)\n",
    "    \n",
    "    ax_heat.set_title(f'SND Matrix (Heatmap) - Step {step_count}')\n",
    "    ax_heat.set_xlabel('Agent Index')\n",
    "    ax_heat.set_ylabel('Agent Index')\n",
    "    \n",
    "    # Set ticks to be integers (Agent 0, Agent 1...)\n",
    "    ax_heat.set_xticks(np.arange(n_agents))\n",
    "    ax_heat.set_yticks(np.arange(n_agents))\n",
    "    \n",
    "    fig_heat.colorbar(im, ax=ax_heat, label='Distance')\n",
    "    \n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(n_agents):\n",
    "        for j in range(n_agents):\n",
    "            val = snd_matrix[i, j]\n",
    "            \n",
    "            # Text color logic: White for dark background (low values), Black for light (high values)\n",
    "            # Viridis: Low values (purple) -> White text. High values (yellow) -> Black text.\n",
    "            # Scale is 0-3. Midpoint roughly 1.5.\n",
    "            text_color = \"white\" if val < 1.0 else \"black\"\n",
    "            \n",
    "            # Print value centered in the cell\n",
    "            ax_heat.text(j, i, f\"{val:.2f}\",\n",
    "                         ha=\"center\", va=\"center\", color=text_color, \n",
    "                         fontsize=8, fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plots[\"Visuals/SND_Heatmap\"] = wandb.Image(fig_heat)\n",
    "    plt.close(fig_heat)\n",
    "\n",
    "    # ==========================================\n",
    "    # 2. BAR CHART (Pairwise Values)\n",
    "    # ==========================================\n",
    "    if len(pairs) > 0:\n",
    "        # Extract values for the unique pairs (upper triangle)\n",
    "        pair_values = [snd_matrix[p[0], p[1]] for p in pairs]\n",
    "        pair_labels = [f\"A{p[0]}-A{p[1]}\" for p in pairs]\n",
    "        \n",
    "        fig_bar, ax_bar = plt.subplots(figsize=(8, 5))\n",
    "        bars = ax_bar.bar(pair_labels, pair_values, color='teal')\n",
    "        \n",
    "        ax_bar.set_title(f'Pairwise Distances - Step {step_count}')\n",
    "        ax_bar.set_ylabel('Distance')\n",
    "        ax_bar.set_ylim(0, 3) \n",
    "        ax_bar.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add values on top of bars\n",
    "        ax_bar.bar_label(bars, fmt='%.2f', padding=3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plots[\"Visuals/SND_BarChart\"] = wandb.Image(fig_bar)\n",
    "        plt.close(fig_bar)\n",
    "\n",
    "    # ==========================================\n",
    "    # 3. NETWORK GRAPH (Topology)\n",
    "    # ==========================================\n",
    "    if len(pairs) > 0:\n",
    "        fig_graph = plt.figure(figsize=(7, 7))\n",
    "        G = nx.Graph()\n",
    "        \n",
    "        # Add edges for unique pairs\n",
    "        for u, v in pairs:\n",
    "            dist = snd_matrix[u, v]\n",
    "            G.add_edge(u, v, weight=dist)\n",
    "\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "        weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "        \n",
    "        # Draw Nodes\n",
    "        nx.draw_networkx_nodes(G, pos, node_size=600, node_color='lightblue')\n",
    "        nx.draw_networkx_labels(G, pos, font_weight='bold')\n",
    "        \n",
    "        # Draw Edges\n",
    "        edges = nx.draw_networkx_edges(G, pos, \n",
    "                               edge_color=weights, \n",
    "                               edge_cmap=plt.cm.viridis, \n",
    "                               width=2,\n",
    "                               edge_vmin=0,\n",
    "                               edge_vmax=3)\n",
    "        \n",
    "        # Draw Edge Labels (The distance values on the lines)\n",
    "        edge_labels = {\n",
    "            (u, v): f\"{d['weight']:.2f}\" \n",
    "            for u, v, d in G.edges(data=True)\n",
    "        }\n",
    "        nx.draw_networkx_edge_labels(\n",
    "            G, pos, \n",
    "            edge_labels=edge_labels, \n",
    "            font_color='black', \n",
    "            font_size=8,\n",
    "            font_weight='bold'\n",
    "        )\n",
    "        \n",
    "        plt.colorbar(edges, label='Distance')\n",
    "        plt.title(f'Interaction Graph - Step {step_count}')\n",
    "        plt.axis('off')\n",
    "        plots[\"Visuals/SND_NetworkGraph\"] = wandb.Image(fig_graph)\n",
    "        plt.close(fig_graph)\n",
    "\n",
    "    return plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c032563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNDVisualizerCallback(Callback):\n",
    "    \"\"\"\n",
    "    A visualization-only callback that computes the SND (Behavioral Distance) matrix\n",
    "    at evaluation time and logs Heatmap, Bar Chart, and Graph visualizations to WandB.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.control_group = None\n",
    "        self.model = None\n",
    "\n",
    "    def on_setup(self):\n",
    "        \"\"\"Auto-detects the agent group and initializes the model wrapper.\"\"\"\n",
    "        if not self.experiment.group_policies:\n",
    "            print(\"\\nWARNING: No group policies found. SND Visualizer disabled.\\n\")\n",
    "            return\n",
    "\n",
    "        # Auto-detect: Simply grab the first available control group\n",
    "        self.control_group = list(self.experiment.group_policies.keys())[0]\n",
    "        \n",
    "        policy = self.experiment.group_policies[self.control_group]\n",
    "        \n",
    "        # We assume 'get_het_model' is available in your scope\n",
    "        self.model = get_het_model(policy)\n",
    "\n",
    "        if self.model is None:\n",
    "             print(f\"\\nWARNING: Could not extract HetModel for group '{self.control_group}'. Visualizer disabled.\\n\")\n",
    "\n",
    "    def _get_agent_actions_for_rollout(self, rollout):\n",
    "        \"\"\"Helper to run the forward pass and get actions for SND computation.\"\"\"\n",
    "        obs = rollout.get((self.control_group, \"observation\"))\n",
    "        actions = []\n",
    "        for i in range(self.model.n_agents):\n",
    "            temp_td = TensorDict(\n",
    "                {(self.control_group, \"observation\"): obs},\n",
    "                batch_size=obs.shape[:-1]\n",
    "            )\n",
    "            # Ensure _forward exists and returns a TensorDict with the output key\n",
    "            action_td = self.model._forward(temp_td, agent_index=i, compute_estimate=False)\n",
    "            actions.append(action_td.get(self.model.out_key))\n",
    "        return actions\n",
    "\n",
    "    def on_evaluation_end(self, rollouts: List[TensorDict]):\n",
    "        \"\"\"Runs at the end of evaluation to compute SND and log plots.\"\"\"\n",
    "        if self.model is None:\n",
    "            return\n",
    "\n",
    "        logs_to_push = {}\n",
    "        first_rollout_snd_matrix = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, r in enumerate(rollouts):\n",
    "                # We only need the matrix from the first rollout for clean visualization\n",
    "                if i > 0: \n",
    "                    break\n",
    "\n",
    "                agent_actions = self._get_agent_actions_for_rollout(r)\n",
    "                \n",
    "                # Compute behavioral distance (Assumed to be available in scope)\n",
    "                # Must return N x N matrix\n",
    "                pairwise_distances_tensor = compute_behavioral_distance(agent_actions, just_mean=False)\n",
    "                \n",
    "                # If the function returns (Time x N x N), average over Time to get (N x N)\n",
    "                if pairwise_distances_tensor.ndim > 2:\n",
    "                    pairwise_distances_tensor = pairwise_distances_tensor.mean(dim=0)\n",
    "\n",
    "                first_rollout_snd_matrix = pairwise_distances_tensor.cpu().numpy()\n",
    "\n",
    "        # Generate and Log Visualizations\n",
    "        if first_rollout_snd_matrix is not None:\n",
    "            visual_logs = generate_snd_visualizations(\n",
    "                snd_matrix=first_rollout_snd_matrix, \n",
    "                n_agents=self.model.n_agents,\n",
    "                step_count=self.experiment.n_iters_performed\n",
    "            )\n",
    "            logs_to_push.update(visual_logs)\n",
    "            \n",
    "            # Update the logger\n",
    "            self.experiment.logger.log(logs_to_push, step=self.experiment.n_iters_performed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73d94d",
   "metadata": {},
   "source": [
    "## Env Setup\n",
    "\n",
    "This code block compiles all the different section of MARl env together to Run the experiment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d8dedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env clean up for W&B\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        print(\"⚠️ Closing lingering W&B run from previous execution...\")\n",
    "        wandb.finish()\n",
    "except Exception as e:\n",
    "    print(f\"W&B Cleanup Warning: {e}\")\n",
    "\n",
    "# Optional: Reset W&B settings to ensure it spawns a fresh process\n",
    "os.environ[\"WANDB_START_METHOD\"] = \"thread\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c891cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(task_name):\n",
    "    benchmarl.models.model_config_registry.update(\n",
    "        {\n",
    "            \"hetcontrolmlpempirical\": HetControlMlpEmpiricalConfig,\n",
    "        }\n",
    "    )\n",
    "    if task_name == \"vmas/navigation\":\n",
    "        # Set the render callback for the navigation case study\n",
    "        VmasTask.render_callback = render_callback\n",
    "\n",
    "def get_experiment(cfg: DictConfig) -> Experiment:\n",
    "    hydra_choices = HydraConfig.get().runtime.choices\n",
    "    task_name = hydra_choices.task\n",
    "    algorithm_name = hydra_choices.algorithm\n",
    "\n",
    "    setup(task_name)\n",
    "\n",
    "    print(f\"\\nAlgorithm: {algorithm_name}, Task: {task_name}\")\n",
    "    # print(\"\\nLoaded config:\\n\") # Optional: Commented out to reduce clutter\n",
    "    # print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    algorithm_config = load_algorithm_config_from_hydra(cfg.algorithm)\n",
    "    experiment_config = load_experiment_config_from_hydra(cfg.experiment)\n",
    "    task_config = load_task_config_from_hydra(cfg.task, task_name)\n",
    "    critic_model_config = load_model_config_from_hydra(cfg.critic_model)\n",
    "    model_config = load_model_config_from_hydra(cfg.model)\n",
    "\n",
    "    if isinstance(algorithm_config, (MappoConfig, IppoConfig, MasacConfig, IsacConfig)):\n",
    "        model_config.probabilistic = True\n",
    "        model_config.scale_mapping = algorithm_config.scale_mapping\n",
    "        algorithm_config.scale_mapping = (\n",
    "            \"relu\"  # The scaling of std_dev will be done in the model\n",
    "        )\n",
    "    else:\n",
    "        model_config.probabilistic = False\n",
    "\n",
    "    experiment = Experiment(\n",
    "        task=task_config,\n",
    "        algorithm_config=algorithm_config,\n",
    "        model_config=model_config,\n",
    "        critic_model_config=critic_model_config,\n",
    "        seed=cfg.seed,\n",
    "        config=experiment_config,\n",
    "        callbacks=[\n",
    "            SndCallback(),\n",
    "            SNDVisualizerCallback(),\n",
    "            # ExtremumSeekingController(\n",
    "            #             control_group=\"agents\",\n",
    "            #             # initial_snd=0.0,\n",
    "            #             dither_magnitude=0.1,\n",
    "            #             dither_frequency_rad_s=1.0,\n",
    "            #             integral_gain=-0.01,\n",
    "            #             high_pass_cutoff_rad_s=1.0,\n",
    "            #             low_pass_cutoff_rad_s=1.0,\n",
    "            #             sampling_period=1.0\n",
    "            # ),\n",
    "            # TrajectorySNDLoggerCallback(control_group=\"agents\"),\n",
    "            NormLoggerCallback(),\n",
    "            ActionSpaceLoss(\n",
    "                use_action_loss=cfg.use_action_loss, action_loss_lr=cfg.action_loss_lr\n",
    "            ),\n",
    "        ]\n",
    "        + (\n",
    "            [\n",
    "                TagCurriculum(\n",
    "                    cfg.simple_tag_freeze_policy_after_frames,\n",
    "                    cfg.simple_tag_freeze_policy,\n",
    "                )\n",
    "            ]\n",
    "            if task_name == \"vmas/simple_tag\"\n",
    "            else []\n",
    "        ),\n",
    "    )\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff428e",
   "metadata": {},
   "source": [
    "## Training Code\n",
    "\n",
    "Trains the model for 200 episodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff608d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from: /home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\n",
      "Running with SND: 0.0\n",
      "\n",
      "Algorithm: ippo, Task: vmas/navigation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__5b0be9f5_25_11_25-15_00_43/wandb/run-20251125_150043-ippo_navigation_hetcontrolmlpempirical__5b0be9f5_25_11_25-15_00_43</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__5b0be9f5_25_11_25-15_00_43' target=\"_blank\">ippo_navigation_hetcontrolmlpempirical__5b0be9f5_25_11_25-15_00_43</a></strong> to <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__5b0be9f5_25_11_25-15_00_43' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__5b0be9f5_25_11_25-15_00_43</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"  # Make sure 'navigation_ippo.yaml' exists in the folder above!\n",
    "SAVE_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/\"\n",
    "\n",
    "save_interval = 600000\n",
    "desired_snd = 0.0\n",
    "max_frame = 6000000\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    print(f\"Creating missing directory: {SAVE_PATH}\")\n",
    "    os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    \"dummy.py\",\n",
    "    f\"model.desired_snd={desired_snd}\",\n",
    "    f\"experiment.max_n_frames={max_frame}\",\n",
    "    f\"experiment.checkpoint_interval={save_interval}\",\n",
    "    f\"experiment.save_folder={SAVE_PATH}\", # FIXED: Removed space after '='\n",
    "]\n",
    "\n",
    "# 3. Define the Hydra wrapper\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def hydra_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Config loaded from: {ABS_CONFIG_PATH}\")\n",
    "        \n",
    "    print(f\"Running with SND: {cfg.model.desired_snd}\")\n",
    "    \n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    experiment.run()\n",
    "\n",
    "# 4. Execute safely\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        hydra_experiment()\n",
    "    except SystemExit:\n",
    "        print(\"Experiment finished successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661f4be9",
   "metadata": {},
   "source": [
    "## Eval Run\n",
    "\n",
    "Single Step eval. from the check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a15dd761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/grad/doc/2027/spatel2/AD2C_testBed/saved_models/model2.pt\n",
      "Initializing model with dummy SND: 0.3\n",
      "\n",
      "Algorithm: ippo, Task: vmas/navigation\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grad/doc/2027/spatel2/AD2C_testBed/wandb/run-20251125_145415-AD2C_testBed</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/AD2C_testBed' target=\"_blank\">AD2C_testBed</a></strong> to <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/AD2C_testBed' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/AD2C_testBed</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Starting Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/agents/reward/episode_reward_max</td><td>▁</td></tr><tr><td>eval/agents/reward/episode_reward_mean</td><td>▁</td></tr><tr><td>eval/agents/reward/episode_reward_min</td><td>▁</td></tr><tr><td>eval/agents/snd</td><td>▁</td></tr><tr><td>eval/reward/episode_len_mean</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_max</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_mean</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_min</td><td>▁</td></tr><tr><td>timers/evaluation_time</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>collection/agents/estimated_snd</td><td>238.9796</td></tr><tr><td>collection/agents/info/agent_collisions</td><td>0</td></tr><tr><td>collection/agents/info/final_rew</td><td>0</td></tr><tr><td>collection/agents/info/pos_rew</td><td>0.00484</td></tr><tr><td>collection/agents/logits</td><td>0.05074</td></tr><tr><td>collection/agents/observation</td><td>0.00852</td></tr><tr><td>collection/agents/out_loc_norm</td><td>0</td></tr><tr><td>collection/agents/reward/episode_reward_max</td><td>2.16559</td></tr><tr><td>collection/agents/reward/episode_reward_mean</td><td>0.48618</td></tr><tr><td>collection/agents/reward/episode_reward_min</td><td>-1.10746</td></tr><tr><td>+41</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">AD2C_testBed</strong> at: <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/AD2C_testBed' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/AD2C_testBed</a><br> View project at: <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a><br>Synced 5 W&B file(s), 4 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/grad/doc/2027/spatel2/AD2C_testBed/wandb/run-20251125_145415-AD2C_testBed/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# CONFIGURATION\n",
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"\n",
    "\n",
    "# Your checkpoint path\n",
    "CHECKPOINT_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/saved_models/model2.pt\"\n",
    "\n",
    "# ==========================================\n",
    "# EVALUATION LOGIC\n",
    "# ==========================================\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    \"eval_script.py\",\n",
    "    f\"experiment.restore_file={CHECKPOINT_PATH}\",\n",
    "    \"experiment.evaluation_episodes=10\",\n",
    "    \"experiment.render=True\",\n",
    "    \"experiment.evaluation_deterministic_actions=True\",\n",
    "    \"experiment.save_folder=null\",\n",
    "    \"model.desired_snd=0.3\" \n",
    "]\n",
    "\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def eval_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Loading model from: {cfg.experiment.restore_file}\")\n",
    "    print(f\"Initializing model with dummy SND: {cfg.model.desired_snd}\")\n",
    "    \n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    \n",
    "    print(\"Model loaded. Starting Evaluation...\")\n",
    "    \n",
    "    experiment._evaluation_loop()\n",
    "    \n",
    "    print(\"Evaluation Complete.\")\n",
    "    experiment.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        eval_experiment()\n",
    "    except SystemExit:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdab9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Testing Environment Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc70fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/checkpoints/checkpoint_12000000.pt\n",
      "Evaluation Setup: 3 Agents, 1 per goal.\n",
      "\n",
      "Algorithm: ippo, Task: vmas/navigation\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/wandb/run-20251122_124239-ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10' target=\"_blank\">ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</a></strong> to <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/agents/reward/episode_reward_max</td><td>▁</td></tr><tr><td>eval/agents/reward/episode_reward_mean</td><td>▁</td></tr><tr><td>eval/agents/reward/episode_reward_min</td><td>▁</td></tr><tr><td>eval/agents/snd</td><td>▁</td></tr><tr><td>eval/reward/episode_len_mean</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_max</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_mean</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_min</td><td>▁</td></tr><tr><td>timers/evaluation_time</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>collection/agents/estimated_snd</td><td>203.30853</td></tr><tr><td>collection/agents/info/agent_collisions</td><td>0</td></tr><tr><td>collection/agents/info/final_rew</td><td>0</td></tr><tr><td>collection/agents/info/pos_rew</td><td>0.01827</td></tr><tr><td>collection/agents/logits</td><td>0.02486</td></tr><tr><td>collection/agents/observation</td><td>-0.00358</td></tr><tr><td>collection/agents/out_loc_norm</td><td>0.0</td></tr><tr><td>collection/agents/reward/episode_reward_max</td><td>2.48916</td></tr><tr><td>collection/agents/reward/episode_reward_mean</td><td>1.03933</td></tr><tr><td>collection/agents/reward/episode_reward_min</td><td>0.22199</td></tr><tr><td>+32</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</strong> at: <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</a><br> View project at: <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/wandb/run-20251122_124239-ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import hydra\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"\n",
    "CHECKPOINT_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/checkpoints/checkpoint_12000000.pt\"\n",
    "\n",
    "# ==========================================\n",
    "# EVALUATION LOGIC\n",
    "# ==========================================\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    \"eval_script.py\",\n",
    "    f\"experiment.restore_file={CHECKPOINT_PATH}\",\n",
    "    \"experiment.evaluation_episodes=10\",\n",
    "    \"experiment.render=True\",\n",
    "    \"experiment.evaluation_deterministic_actions=True\",\n",
    "    \"experiment.save_folder=null\",\n",
    "    \"model.desired_snd=0.3\",\n",
    "    \n",
    "    # --- THE CHANGE ---\n",
    "    # Assuming you have 3 agents total. \n",
    "    # Setting this to 3 means all 3 agents go to the SAME goal (1 goal total).\n",
    "    \"task.agents_with_same_goal=1\" \n",
    "]\n",
    "\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def eval_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Loading model from: {cfg.experiment.restore_file}\")\n",
    "    \n",
    "    # Verification print\n",
    "    print(f\"Evaluation Setup: {cfg.task.n_agents} Agents, {cfg.task.agents_with_same_goal} per goal.\")\n",
    "    \n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    print(\"Starting Evaluation...\")\n",
    "    experiment._evaluation_loop()\n",
    "    print(\"Evaluation Complete.\")\n",
    "    experiment.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        eval_experiment()\n",
    "    except SystemExit:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c36dba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train from another checkpoint with different Task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a57551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming with SND: 1.0\n",
      "Agents sharing a goal: 1\n",
      "\n",
      "Algorithm: ippo, Task: vmas/navigation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msvarp\u001b[0m (\u001b[33msvarp-university-of-massachusetts-lowell\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13/wandb/run-20251122_125420-ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13' target=\"_blank\">ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13</a></strong> to <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ SUCCESS: Extremum Seeking Controller initialized for group 'agents'.\n",
      "\n",
      "SUCCESS: Logger initialized for HetControlMlpEscSnd on group 'agents'.\n",
      "Experiment finished successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: ['model.desired_snd=1.0', 'experiment.restore_file=/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13/checkpoints/checkpoint_12000000.pt', 'experiment.max_n_frames=15000000', 'task.agents_with_same_goal=1', 'experiment.save_folder=null']\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2439253/1461699133.py\", line 32, in hydra_experiment\n",
      "    experiment = get_experiment(cfg=cfg)\n",
      "  File \"/tmp/ipykernel_2439253/1144324724.py\", line 39, in get_experiment\n",
      "    experiment = Experiment(\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/experiment.py\", line 332, in __init__\n",
      "    self._load_experiment()\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/experiment.py\", line 792, in _load_experiment\n",
      "    loaded_dict: OrderedDict = torch.load(self.config.restore_file)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/serialization.py\", line 771, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/serialization.py\", line 270, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/serialization.py\", line 251, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13/checkpoints/checkpoint_12000000.pt'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"\n",
    "CHECKPOINT_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/checkpoints/checkpoint_12000000.pt\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. RUN LOGIC\n",
    "# ==========================================\n",
    "new_max_frames = 15000000 \n",
    "desired_snd = 1.0\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    \"run_script.py\",\n",
    "    f\"model.desired_snd={desired_snd}\",\n",
    "    f\"experiment.restore_file={CHECKPOINT_PATH}\",\n",
    "    f\"experiment.max_n_frames={new_max_frames}\",\n",
    "    \n",
    "    # --- TASK CONFIGURATION ---\n",
    "    \"task.agents_with_same_goal=1\", \n",
    "    \"experiment.save_folder=null\"\n",
    "]\n",
    "\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def hydra_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Resuming with SND: {cfg.model.desired_snd}\")\n",
    "    print(f\"Agents sharing a goal: {cfg.task.agents_with_same_goal}\")\n",
    "    \n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    experiment.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        hydra_experiment()\n",
    "    except SystemExit:\n",
    "        print(\"Experiment finished successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996714c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad2c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc6ae0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/rl/torchrl/data/replay_buffers/samplers.py:23: UserWarning: Failed to import torchrl C++ binaries. Some modules (eg, prioritized replay buffers) may not work with your installation. If you installed TorchRL from PyPI, please report the bug on TorchRL github. If you installed TorchRL locally and/or in development mode, check that you have all the required compiling packages.\n",
      "  warnings.warn(EXTENSION_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import hydra\n",
    "import wandb\n",
    "import sys\n",
    "import hydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# Benchmarl & Project Imports\n",
    "import benchmarl.models\n",
    "from benchmarl.algorithms import *\n",
    "from benchmarl.environments import VmasTask\n",
    "from benchmarl.experiment import Experiment\n",
    "from benchmarl.hydra_config import (\n",
    "    load_algorithm_config_from_hydra,\n",
    "    load_experiment_config_from_hydra,\n",
    "    load_task_config_from_hydra,\n",
    "    load_model_config_from_hydra,\n",
    ")\n",
    "\n",
    "# Custom Callbacks\n",
    "from het_control.callback import *\n",
    "from het_control.environments.vmas import render_callback\n",
    "from het_control.models.het_control_mlp_empirical import HetControlMlpEmpiricalConfig\n",
    "from het_control.callbacks.esc_callback import ExtremumSeekingController\n",
    "from het_control.callbacks.sndESLogger import TrajectorySNDLoggerCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb8c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8dedd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Env clean up for W&B\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        print(\"⚠️ Closing lingering W&B run from previous execution...\")\n",
    "        wandb.finish()\n",
    "except Exception as e:\n",
    "    print(f\"W&B Cleanup Warning: {e}\")\n",
    "\n",
    "# Optional: Reset W&B settings to ensure it spawns a fresh process\n",
    "os.environ[\"WANDB_START_METHOD\"] = \"thread\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c891cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. EXPERIMENT LOGIC\n",
    "\n",
    "def setup(task_name):\n",
    "    benchmarl.models.model_config_registry.update(\n",
    "        {\n",
    "            \"hetcontrolmlpempirical\": HetControlMlpEmpiricalConfig,\n",
    "        }\n",
    "    )\n",
    "    if task_name == \"vmas/navigation\":\n",
    "        # Set the render callback for the navigation case study\n",
    "        VmasTask.render_callback = render_callback\n",
    "\n",
    "def get_experiment(cfg: DictConfig) -> Experiment:\n",
    "    hydra_choices = HydraConfig.get().runtime.choices\n",
    "    task_name = hydra_choices.task\n",
    "    algorithm_name = hydra_choices.algorithm\n",
    "\n",
    "    setup(task_name)\n",
    "\n",
    "    print(f\"\\nAlgorithm: {algorithm_name}, Task: {task_name}\")\n",
    "    # print(\"\\nLoaded config:\\n\") # Optional: Commented out to reduce clutter\n",
    "    # print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    algorithm_config = load_algorithm_config_from_hydra(cfg.algorithm)\n",
    "    experiment_config = load_experiment_config_from_hydra(cfg.experiment)\n",
    "    task_config = load_task_config_from_hydra(cfg.task, task_name)\n",
    "    critic_model_config = load_model_config_from_hydra(cfg.critic_model)\n",
    "    model_config = load_model_config_from_hydra(cfg.model)\n",
    "\n",
    "    if isinstance(algorithm_config, (MappoConfig, IppoConfig, MasacConfig, IsacConfig)):\n",
    "        model_config.probabilistic = True\n",
    "        model_config.scale_mapping = algorithm_config.scale_mapping\n",
    "        algorithm_config.scale_mapping = (\n",
    "            \"relu\"  # The scaling of std_dev will be done in the model\n",
    "        )\n",
    "    else:\n",
    "        model_config.probabilistic = False\n",
    "\n",
    "    experiment = Experiment(\n",
    "        task=task_config,\n",
    "        algorithm_config=algorithm_config,\n",
    "        model_config=model_config,\n",
    "        critic_model_config=critic_model_config,\n",
    "        seed=cfg.seed,\n",
    "        config=experiment_config,\n",
    "        callbacks=[\n",
    "            SndCallback(),\n",
    "            ExtremumSeekingController(\n",
    "                        control_group=\"agents\",\n",
    "                        initial_snd=0.3,\n",
    "                        dither_magnitude=0.1,\n",
    "                        dither_frequency_rad_s=1.0,\n",
    "                        integral_gain=-0.001,\n",
    "                        high_pass_cutoff_rad_s=1.0,\n",
    "                        low_pass_cutoff_rad_s=1.0,\n",
    "                        sampling_period=1.0\n",
    "            ),\n",
    "            TrajectorySNDLoggerCallback(control_group=\"agents\"),\n",
    "            NormLoggerCallback(),\n",
    "            ActionSpaceLoss(\n",
    "                use_action_loss=cfg.use_action_loss, action_loss_lr=cfg.action_loss_lr\n",
    "            ),\n",
    "        ]\n",
    "        + (\n",
    "            [\n",
    "                TagCurriculum(\n",
    "                    cfg.simple_tag_freeze_policy_after_frames,\n",
    "                    cfg.simple_tag_freeze_policy,\n",
    "                )\n",
    "            ]\n",
    "            if task_name == \"vmas/simple_tag\"\n",
    "            else []\n",
    "        ),\n",
    "    )\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff608d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 1. PATH CONFIGURATION\n",
    "\n",
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"  # Make sure 'navigation_ippo.yaml' exists in the folder above!\n",
    "SAVE_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/\"\n",
    "# 2. RUN LOGIC\n",
    "save_interval = 6000000\n",
    "desired_snd = 0.6\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    print(f\"Creating missing directory: {SAVE_PATH}\")\n",
    "    os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    f\"model.desired_snd={desired_snd}\",\n",
    "    f\"experiment.checkpoint_interval={save_interval}\",\n",
    "    f\"experiment.save_folder= {SAVE_PATH}\",\n",
    "]\n",
    "\n",
    "\n",
    "# 3. Define the Hydra wrapper with the ABSOLUTE path\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def hydra_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Config loaded from: {ABS_CONFIG_PATH}\")\n",
    "    cfg.model.desired_snd = float(sys.argv[1])\n",
    "    print(f\"Running with SND: {cfg.model.desired_snd}\")\n",
    "    \n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    experiment.run()\n",
    "\n",
    "# 4. Execute safely\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        hydra_experiment()\n",
    "    except SystemExit:\n",
    "        print(\"Experiment finished successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70f2686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06616afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a15dd761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/checkpoints/checkpoint_12000000.pt\n",
      "Initializing model with dummy SND: 0.3\n",
      "\n",
      "Algorithm: ippo, Task: vmas/navigation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msvarp\u001b[0m (\u001b[33msvarp-university-of-massachusetts-lowell\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/wandb/run-20251122_123444-ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10' target=\"_blank\">ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</a></strong> to <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded. Starting Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/agents/reward/episode_reward_max</td><td>▁</td></tr><tr><td>eval/agents/reward/episode_reward_mean</td><td>▁</td></tr><tr><td>eval/agents/reward/episode_reward_min</td><td>▁</td></tr><tr><td>eval/agents/snd</td><td>▁</td></tr><tr><td>eval/reward/episode_len_mean</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_max</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_mean</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_min</td><td>▁</td></tr><tr><td>timers/evaluation_time</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>collection/agents/estimated_snd</td><td>203.30853</td></tr><tr><td>collection/agents/info/agent_collisions</td><td>0</td></tr><tr><td>collection/agents/info/final_rew</td><td>0</td></tr><tr><td>collection/agents/info/pos_rew</td><td>0.01827</td></tr><tr><td>collection/agents/logits</td><td>0.02486</td></tr><tr><td>collection/agents/observation</td><td>-0.00358</td></tr><tr><td>collection/agents/out_loc_norm</td><td>0.0</td></tr><tr><td>collection/agents/reward/episode_reward_max</td><td>2.48916</td></tr><tr><td>collection/agents/reward/episode_reward_mean</td><td>1.03933</td></tr><tr><td>collection/agents/reward/episode_reward_min</td><td>0.22199</td></tr><tr><td>+32</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</strong> at: <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</a><br> View project at: <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/wandb/run-20251122_123444-ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# CONFIGURATION\n",
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"\n",
    "\n",
    "# Your checkpoint path\n",
    "CHECKPOINT_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/checkpoints/checkpoint_12000000.pt\"\n",
    "\n",
    "# ==========================================\n",
    "# EVALUATION LOGIC\n",
    "# ==========================================\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    \"eval_script.py\",\n",
    "    f\"experiment.restore_file={CHECKPOINT_PATH}\",\n",
    "    \"experiment.evaluation_episodes=10\",\n",
    "    \"experiment.render=True\",\n",
    "    \"experiment.evaluation_deterministic_actions=True\",\n",
    "    \n",
    "    # 1. DISABLE SAVE FOLDER (Prevents the \"Both specified\" error)\n",
    "    \"experiment.save_folder=null\",\n",
    "    \n",
    "    # 2. PROVIDE SND VALUE (Prevents the \"NoneType\" error)\n",
    "    # The model class needs this to initialize. Any float works here \n",
    "    # because the actual weights will be overwritten by the checkpoint.\n",
    "    \"model.desired_snd=0.3\" \n",
    "]\n",
    "\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def eval_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Loading model from: {cfg.experiment.restore_file}\")\n",
    "    print(f\"Initializing model with dummy SND: {cfg.model.desired_snd}\")\n",
    "    \n",
    "    # Initialize experiment\n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    \n",
    "    print(\"Model loaded. Starting Evaluation...\")\n",
    "    \n",
    "    # Run Evaluation Loop\n",
    "    experiment._evaluation_loop()\n",
    "    \n",
    "    print(\"Evaluation Complete.\")\n",
    "    experiment.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        eval_experiment()\n",
    "    except SystemExit:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdab9431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Testing Environment Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc70fd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/checkpoints/checkpoint_12000000.pt\n",
      "Evaluation Setup: 3 Agents, 1 per goal.\n",
      "\n",
      "Algorithm: ippo, Task: vmas/navigation\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/wandb/run-20251122_124239-ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10' target=\"_blank\">ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</a></strong> to <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/agents/reward/episode_reward_max</td><td>▁</td></tr><tr><td>eval/agents/reward/episode_reward_mean</td><td>▁</td></tr><tr><td>eval/agents/reward/episode_reward_min</td><td>▁</td></tr><tr><td>eval/agents/snd</td><td>▁</td></tr><tr><td>eval/reward/episode_len_mean</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_max</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_mean</td><td>▁</td></tr><tr><td>eval/reward/episode_reward_min</td><td>▁</td></tr><tr><td>timers/evaluation_time</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>collection/agents/estimated_snd</td><td>203.30853</td></tr><tr><td>collection/agents/info/agent_collisions</td><td>0</td></tr><tr><td>collection/agents/info/final_rew</td><td>0</td></tr><tr><td>collection/agents/info/pos_rew</td><td>0.01827</td></tr><tr><td>collection/agents/logits</td><td>0.02486</td></tr><tr><td>collection/agents/observation</td><td>-0.00358</td></tr><tr><td>collection/agents/out_loc_norm</td><td>0.0</td></tr><tr><td>collection/agents/reward/episode_reward_max</td><td>2.48916</td></tr><tr><td>collection/agents/reward/episode_reward_mean</td><td>1.03933</td></tr><tr><td>collection/agents/reward/episode_reward_min</td><td>0.22199</td></tr><tr><td>+32</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</strong> at: <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10</a><br> View project at: <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/wandb/run-20251122_124239-ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import hydra\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "# ==========================================\n",
    "# CONFIGURATION\n",
    "# ==========================================\n",
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"\n",
    "CHECKPOINT_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/checkpoints/checkpoint_12000000.pt\"\n",
    "\n",
    "# ==========================================\n",
    "# EVALUATION LOGIC\n",
    "# ==========================================\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    \"eval_script.py\",\n",
    "    f\"experiment.restore_file={CHECKPOINT_PATH}\",\n",
    "    \"experiment.evaluation_episodes=10\",\n",
    "    \"experiment.render=True\",\n",
    "    \"experiment.evaluation_deterministic_actions=True\",\n",
    "    \"experiment.save_folder=null\",\n",
    "    \"model.desired_snd=0.3\",\n",
    "    \n",
    "    # --- THE CHANGE ---\n",
    "    # Assuming you have 3 agents total. \n",
    "    # Setting this to 3 means all 3 agents go to the SAME goal (1 goal total).\n",
    "    \"task.agents_with_same_goal=1\" \n",
    "]\n",
    "\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def eval_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Loading model from: {cfg.experiment.restore_file}\")\n",
    "    \n",
    "    # Verification print\n",
    "    print(f\"Evaluation Setup: {cfg.task.n_agents} Agents, {cfg.task.agents_with_same_goal} per goal.\")\n",
    "    \n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    print(\"Starting Evaluation...\")\n",
    "    experiment._evaluation_loop()\n",
    "    print(\"Evaluation Complete.\")\n",
    "    experiment.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        eval_experiment()\n",
    "    except SystemExit:\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c36dba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train from another checkpoint with different Task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a57551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming with SND: 1.0\n",
      "Agents sharing a goal: 1\n",
      "\n",
      "Algorithm: ippo, Task: vmas/navigation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msvarp\u001b[0m (\u001b[33msvarp-university-of-massachusetts-lowell\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13/wandb/run-20251122_125420-ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13' target=\"_blank\">ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13</a></strong> to <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ SUCCESS: Extremum Seeking Controller initialized for group 'agents'.\n",
      "\n",
      "SUCCESS: Logger initialized for HetControlMlpEscSnd on group 'agents'.\n",
      "Experiment finished successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error executing job with overrides: ['model.desired_snd=1.0', 'experiment.restore_file=/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13/checkpoints/checkpoint_12000000.pt', 'experiment.max_n_frames=15000000', 'task.agents_with_same_goal=1', 'experiment.save_folder=null']\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2439253/1461699133.py\", line 32, in hydra_experiment\n",
      "    experiment = get_experiment(cfg=cfg)\n",
      "  File \"/tmp/ipykernel_2439253/1144324724.py\", line 39, in get_experiment\n",
      "    experiment = Experiment(\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/experiment.py\", line 332, in __init__\n",
      "    self._load_experiment()\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/experiment.py\", line 792, in _load_experiment\n",
      "    loaded_dict: OrderedDict = torch.load(self.config.restore_file)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/serialization.py\", line 771, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/serialization.py\", line 270, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/serialization.py\", line 251, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__e3667b5c_25_11_21-15_00_13/checkpoints/checkpoint_12000000.pt'\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"\n",
    "CHECKPOINT_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__8abb18cb_25_11_21-18_17_10/checkpoints/checkpoint_12000000.pt\"\n",
    "\n",
    "# ==========================================\n",
    "# 2. RUN LOGIC\n",
    "# ==========================================\n",
    "new_max_frames = 15000000 \n",
    "desired_snd = 1.0\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    \"run_script.py\",\n",
    "    f\"model.desired_snd={desired_snd}\",\n",
    "    f\"experiment.restore_file={CHECKPOINT_PATH}\",\n",
    "    f\"experiment.max_n_frames={new_max_frames}\",\n",
    "    \n",
    "    # --- TASK CONFIGURATION ---\n",
    "    \"task.agents_with_same_goal=1\", \n",
    "    \"experiment.save_folder=null\"\n",
    "]\n",
    "\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def hydra_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Resuming with SND: {cfg.model.desired_snd}\")\n",
    "    print(f\"Agents sharing a goal: {cfg.task.agents_with_same_goal}\")\n",
    "    \n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    experiment.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        hydra_experiment()\n",
    "    except SystemExit:\n",
    "        print(\"Experiment finished successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996714c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad2c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

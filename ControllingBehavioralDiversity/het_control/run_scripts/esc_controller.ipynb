{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1453821b",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786c7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import io\n",
    "\n",
    "# Hydra\n",
    "import hydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "from hydra.core.global_hydra import GlobalHydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "\n",
    "# WandB / Logging\n",
    "import wandb\n",
    "\n",
    "# BenchMARL\n",
    "import benchmarl.models\n",
    "from benchmarl.algorithms import *\n",
    "from benchmarl.environments import VmasTask\n",
    "from benchmarl.experiment import Experiment\n",
    "from benchmarl.hydra_config import (\n",
    "    load_algorithm_config_from_hydra,\n",
    "    load_experiment_config_from_hydra,\n",
    "    load_task_config_from_hydra,\n",
    "    load_model_config_from_hydra,\n",
    ")\n",
    "from benchmarl.experiment.callback import Callback\n",
    "\n",
    "# Het-Control\n",
    "from het_control.callback import *\n",
    "from het_control.environments.vmas import render_callback\n",
    "from het_control.models.het_control_mlp_empirical import (\n",
    "    HetControlMlpEmpiricalConfig,\n",
    "    HetControlMlpEmpirical,\n",
    ")\n",
    "from het_control.callbacks.sndESLogger import TrajectorySNDLoggerCallback\n",
    "from het_control.callbacks.utils import *\n",
    "from het_control.snd import compute_behavioral_distance\n",
    "\n",
    "# Scientific\n",
    "import numpy as np\n",
    "import torch\n",
    "from tensordict import TensorDict, TensorDictBase\n",
    "from typing import List, Dict, Any, Callable, Union\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8da2e",
   "metadata": {},
   "source": [
    "## SND Visualization Plot\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53853c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNDHeatmapVisualizer:\n",
    "    def __init__(self, key_name=\"Visuals/SND_Heatmap\"):\n",
    "        self.key_name = key_name\n",
    "\n",
    "    def generate(self, snd_matrix, step_count):\n",
    "        # --- Fix diagonal ---\n",
    "        snd_matrix = snd_matrix.copy()\n",
    "        np.fill_diagonal(snd_matrix, 0.0)\n",
    "\n",
    "        # --- Enforce symmetry ---\n",
    "        snd_matrix = (snd_matrix + snd_matrix.T) / 2.0\n",
    "\n",
    "        n_agents = snd_matrix.shape[0]\n",
    "        agent_labels = [f\"Agent {i+1}\" for i in range(n_agents)]\n",
    "        \n",
    "        # --- Compute SND = average pairwise distance ---\n",
    "        iu = np.triu_indices(n_agents, k=1)     # upper triangle (i < j)\n",
    "        snd_value = float(np.mean(snd_matrix[iu]))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(6, 5))\n",
    "\n",
    "        im = ax.imshow(\n",
    "            snd_matrix,\n",
    "            cmap=\"viridis\",\n",
    "            interpolation=\"nearest\",\n",
    "            vmin=0, vmax=3\n",
    "        )\n",
    "\n",
    "        # --- Updated title with SND ---\n",
    "        ax.set_title(f\"SND: {snd_value:.3f}  –  Step {step_count}\")\n",
    "\n",
    "        ax.set_xticks(np.arange(n_agents))\n",
    "        ax.set_yticks(np.arange(n_agents))\n",
    "        ax.set_xticklabels(agent_labels)\n",
    "        ax.set_yticklabels(agent_labels)\n",
    "        plt.setp(ax.get_xticklabels(), rotation=30, ha=\"right\")\n",
    "\n",
    "        fig.colorbar(im, ax=ax, label=\"Distance\")\n",
    "\n",
    "        # Cell labels\n",
    "        for i in range(n_agents):\n",
    "            for j in range(n_agents):\n",
    "                val = snd_matrix[i, j]\n",
    "                text_color = \"white\" if val < 1.0 else \"black\"\n",
    "\n",
    "                ax.text(\n",
    "                    j, i, f\"{val:.2f}\",\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=text_color,\n",
    "                    fontsize=9, fontweight=\"bold\"\n",
    "                )\n",
    "\n",
    "        plt.tight_layout()\n",
    "        img = wandb.Image(fig)\n",
    "        plt.close(fig)\n",
    "        return {self.key_name: img}\n",
    "\n",
    "\n",
    "class SNDBarChartVisualizer:\n",
    "    def __init__(self, key_name=\"Visuals/SND_BarChart\"):\n",
    "        self.key_name = key_name\n",
    "\n",
    "    def generate(self, snd_matrix, step_count):\n",
    "        n_agents = snd_matrix.shape[0]\n",
    "\n",
    "        # --- Fix diagonal ---\n",
    "        snd_matrix = snd_matrix.copy()\n",
    "        np.fill_diagonal(snd_matrix, 0.0)\n",
    "\n",
    "        # --- Enforce symmetry ---\n",
    "        snd_matrix = (snd_matrix + snd_matrix.T) / 2.0\n",
    "\n",
    "        # --- Create agent pairs i < j ---\n",
    "        pairs = [(i, j) for i in range(n_agents) for j in range(i + 1, n_agents)]\n",
    "        if not pairs:\n",
    "            return {}\n",
    "\n",
    "        pair_values = [float(snd_matrix[i, j]) for i, j in pairs]\n",
    "        pair_labels = [f\"A{i+1}-A{j+1}\" for i, j in pairs]\n",
    "\n",
    "        # --- Compute SND (mean of pairwise distances) ---\n",
    "        snd_value = float(np.mean(pair_values))\n",
    "\n",
    "        # --- Plot ---\n",
    "        fig, ax = plt.subplots(figsize=(8, 5))\n",
    "        bars = ax.bar(pair_labels, pair_values, color=\"teal\")\n",
    "\n",
    "        ax.set_title(f\"SND: {snd_value:.3f}  –  Step {step_count}\")\n",
    "        ax.set_ylabel(\"Distance\")\n",
    "        ax.set_ylim(0, 3)\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "        # Add value labels above bars\n",
    "        ax.bar_label(bars, fmt=\"%.2f\", padding=3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        img = wandb.Image(fig)\n",
    "        plt.close(fig)\n",
    "        return {self.key_name: img}\n",
    "\n",
    "\n",
    "class SNDGraphVisualizer:\n",
    "    def __init__(self, key_name=\"Visuals/SND_NetworkGraph\"):\n",
    "        self.key_name = key_name\n",
    "\n",
    "    def generate(self, snd_matrix, step_count):\n",
    "        n_agents = snd_matrix.shape[0]\n",
    "\n",
    "        # --- Fix diagonal ---\n",
    "        snd_matrix = snd_matrix.copy()\n",
    "        np.fill_diagonal(snd_matrix, 0.0)\n",
    "\n",
    "        # --- Enforce symmetry ---\n",
    "        snd_matrix = (snd_matrix + snd_matrix.T) / 2.0\n",
    "\n",
    "        # --- Create edges only for i < j ---\n",
    "        pairs = [(i, j) for i in range(n_agents) for j in range(i + 1, n_agents)]\n",
    "        if not pairs:\n",
    "            return {}\n",
    "\n",
    "        # Distances for each pair\n",
    "        pair_values = [float(snd_matrix[i, j]) for i, j in pairs]\n",
    "\n",
    "        # --- Compute SND (avg distance) ---\n",
    "        snd_value = float(np.mean(pair_values))\n",
    "\n",
    "        # Build graph\n",
    "        fig = plt.figure(figsize=(7, 7))\n",
    "        G = nx.Graph()\n",
    "\n",
    "        # Add edges with weights\n",
    "        for i, j in pairs:\n",
    "            G.add_edge(i, j, weight=float(snd_matrix[i, j]))\n",
    "\n",
    "        # Layout\n",
    "        pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "        # Edge weights for coloring\n",
    "        weights = [G[u][v]['weight'] for u, v in G.edges()]\n",
    "\n",
    "        # --- Draw Nodes ---\n",
    "        nx.draw_networkx_nodes(\n",
    "            G, pos, node_size=750, node_color='lightblue'\n",
    "        )\n",
    "\n",
    "        # Label nodes as Agent 1, Agent 2, ...\n",
    "        label_mapping = {i: f\"A{i+1}\" for i in range(n_agents)}\n",
    "        nx.draw_networkx_labels(\n",
    "            G, pos, labels=label_mapping, font_size=12, font_weight='bold'\n",
    "        )\n",
    "\n",
    "        # --- Draw edges ---\n",
    "        edges = nx.draw_networkx_edges(\n",
    "            G, pos,\n",
    "            edge_color=weights,\n",
    "            edge_cmap=plt.cm.viridis,\n",
    "            width=2,\n",
    "            edge_vmin=0,\n",
    "            edge_vmax=3\n",
    "        )\n",
    "\n",
    "        # --- Draw edge labels ---\n",
    "        edge_labels = {(i, j): f\"{snd_matrix[i, j]:.2f}\" for i, j in pairs}\n",
    "\n",
    "        nx.draw_networkx_edge_labels(\n",
    "            G,\n",
    "            pos,\n",
    "            edge_labels=edge_labels,\n",
    "            font_color='black',\n",
    "            font_size=9,\n",
    "            font_weight='bold'\n",
    "        )\n",
    "\n",
    "        # Colorbar\n",
    "        plt.colorbar(edges, label='Distance')\n",
    "\n",
    "        # Title with SND value\n",
    "        plt.title(f\"SND: {snd_value:.3f}  –  Step {step_count}\", fontsize=14)\n",
    "        plt.axis('off')\n",
    "\n",
    "        img = wandb.Image(fig)\n",
    "        plt.close(fig)\n",
    "        return {self.key_name: img}\n",
    "\n",
    "\n",
    "class SNDVisualizationManager:\n",
    "    \"\"\"\n",
    "    Manages the individual visualizers.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.visualizers = [\n",
    "            SNDHeatmapVisualizer(),\n",
    "            SNDBarChartVisualizer(),\n",
    "            SNDGraphVisualizer()\n",
    "        ]\n",
    "\n",
    "    def generate_all(self, snd_matrix, step_count):\n",
    "        all_plots = {}\n",
    "        for visualizer in self.visualizers:\n",
    "            try:\n",
    "                plots = visualizer.generate(snd_matrix, step_count)\n",
    "                all_plots.update(plots)\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating {visualizer.__class__.__name__}: {e}\")\n",
    "        return all_plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6262e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SNDVisualizerCallback(Callback):\n",
    "    \"\"\"\n",
    "    Computes the SND matrix and uses the Manager to log visualizations.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.control_group = None\n",
    "        self.model = None\n",
    "        # Initialize the manager that holds the 3 plot classes\n",
    "        self.viz_manager = SNDVisualizationManager()\n",
    "\n",
    "    def on_setup(self):\n",
    "        \"\"\"Auto-detects the agent group and initializes the model wrapper.\"\"\"\n",
    "        if not self.experiment.group_policies:\n",
    "            print(\"\\nWARNING: No group policies found. SND Visualizer disabled.\\n\")\n",
    "            return\n",
    "\n",
    "        self.control_group = list(self.experiment.group_policies.keys())[0]\n",
    "        policy = self.experiment.group_policies[self.control_group]\n",
    "        \n",
    "        # Ensure 'get_het_model' is imported or available in this scope\n",
    "        self.model = get_het_model(policy)\n",
    "\n",
    "        if self.model is None:\n",
    "             print(f\"\\nWARNING: Could not extract HetModel for group '{self.control_group}'. Visualizer disabled.\\n\")\n",
    "\n",
    "    def _get_agent_actions_for_rollout(self, rollout):\n",
    "        \"\"\"Helper to run the forward pass and get actions for SND computation.\"\"\"\n",
    "        obs = rollout.get((self.control_group, \"observation\"))\n",
    "        actions = []\n",
    "        for i in range(self.model.n_agents):\n",
    "            temp_td = TensorDict(\n",
    "                {(self.control_group, \"observation\"): obs},\n",
    "                batch_size=obs.shape[:-1]\n",
    "            )\n",
    "            action_td = self.model._forward(temp_td, agent_index=i, compute_estimate=False)\n",
    "            actions.append(action_td.get(self.model.out_key))\n",
    "        return actions\n",
    "\n",
    "    def on_evaluation_end(self, rollouts: List[TensorDict]):\n",
    "        \"\"\"Runs at the end of evaluation to compute SND and log plots.\"\"\"\n",
    "        if self.model is None:\n",
    "            return\n",
    "\n",
    "        logs_to_push = {}\n",
    "        first_rollout_snd_matrix = None\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, r in enumerate(rollouts):\n",
    "                # We only need the matrix from the first rollout for clean visualization\n",
    "                if i > 0: \n",
    "                    break\n",
    "\n",
    "                agent_actions = self._get_agent_actions_for_rollout(r)\n",
    "                \n",
    "                # Ensure 'compute_behavioral_distance' is imported/available\n",
    "                pairwise_distances_tensor = compute_behavioral_distance(agent_actions, just_mean=False)\n",
    "                \n",
    "                if pairwise_distances_tensor.ndim > 2:\n",
    "                    pairwise_distances_tensor = pairwise_distances_tensor.mean(dim=0)\n",
    "\n",
    "                first_rollout_snd_matrix = pairwise_distances_tensor.cpu().numpy()\n",
    "\n",
    "        # Generate and Log Visualizations via the Manager\n",
    "        if first_rollout_snd_matrix is not None:\n",
    "            visual_logs = self.viz_manager.generate_all(\n",
    "                snd_matrix=first_rollout_snd_matrix, \n",
    "                step_count=self.experiment.n_iters_performed\n",
    "            )\n",
    "            logs_to_push.update(visual_logs)\n",
    "            \n",
    "            # Update the logger\n",
    "            self.experiment.logger.log(logs_to_push, step=self.experiment.n_iters_performed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bb8f36",
   "metadata": {},
   "source": [
    "## ESC Controller\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36af714",
   "metadata": {},
   "outputs": [],
   "source": [
    "class esc:\n",
    "    # cutoff_frequencies in rad/s\n",
    "    def __init__(\n",
    "        self,\n",
    "        sampling_period,\n",
    "        disturbance_frequency,\n",
    "        disturbance_magnitude,\n",
    "        integrator_gain,\n",
    "        initial_search_value,\n",
    "        high_pass_cutoff_frequency,\n",
    "        low_pass_cutoff_frequency,\n",
    "        use_adapter,\n",
    "    ):\n",
    "        self.dt = sampling_period  # in [s]\n",
    "        self.disturbance_frequency = disturbance_frequency  # in rad/s\n",
    "        self.disturbance_magnitude = disturbance_magnitude\n",
    "        # negative for gradient descent\n",
    "        self.integrator_gain = integrator_gain\n",
    "        self.initial_search_value = initial_search_value\n",
    "        # boolean, true or false (use the adapter or not)\n",
    "        self.use_adapter = use_adapter\n",
    "\n",
    "        self.high_pass_filter = High_pass_filter_first_order(\n",
    "            sampling_period, high_pass_cutoff_frequency, 0, 0\n",
    "        )\n",
    "        self.low_pass_filter = Low_pass_filter_first_order(\n",
    "            sampling_period, low_pass_cutoff_frequency, 0\n",
    "        )\n",
    "        # current phase of perturbation\n",
    "        self.wt = 0\n",
    "\n",
    "        self.min_setpoint = 0.0\n",
    "        \n",
    "        # integrator output\n",
    "        self.integral = 0\n",
    "        # estimated second moment\n",
    "        self.m2 = 0\n",
    "        self.b2 = 0.8\n",
    "        # to prevent from dividing by zero\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "        return\n",
    "\n",
    "    def update(self, cost):\n",
    "        high_pass_output = self.high_pass_filter.apply(cost)\n",
    "        low_pass_input = high_pass_output * np.sin(self.wt)\n",
    "        low_pass_output = self.low_pass_filter.apply(low_pass_input)\n",
    "\n",
    "        # if self.use_adapter:\n",
    "        #     # Estimate the second moment (variance) of the gradient\n",
    "        #     self.m2 = self.b2 * self.m2 + (1 - self.b2) * np.power(low_pass_output, 2)\n",
    "        #     # Always normalize the gradient by its root mean square\n",
    "        #     gradient = low_pass_output / (np.sqrt(self.m2) + self.epsilon)\n",
    "        # else:\n",
    "        #     gradient = low_pass_output\n",
    "\n",
    "        self.m2 = self.b2 * self.m2 + (1 - self.b2) * np.power(low_pass_output, 2)\n",
    "        gradient_mag = np.sqrt(self.m2)\n",
    "\n",
    "        threshold = 0.2\n",
    "\n",
    "        high_gain = -0.025  #0.1\n",
    "        # low_gain =  -0.0015  #0.05\n",
    "\n",
    "        if self.use_adapter:\n",
    "            if gradient_mag > threshold:\n",
    "                gain = high_gain\n",
    "            else:\n",
    "                gain = self.integrator_gain\n",
    "        else:\n",
    "            gain = self.integrator_gain\n",
    "\n",
    "\n",
    "        self.integral += gain * low_pass_output * self.dt\n",
    "        # setpoint = self.initial_search_value + self.integral\n",
    "        \n",
    "        # setpoint = max(setpoint, self.min_setpoint)\n",
    "\n",
    "        setpoint_r = self.initial_search_value + self.integral\n",
    "\n",
    "        # 2. Apply the clamp to get the actual setpoint\n",
    "        setpoint = max(setpoint_r, self.min_setpoint)\n",
    "\n",
    "        # 3. Correct the integrator state if clamping occurred\n",
    "        if setpoint < self.min_setpoint:\n",
    "            self.integral = self.min_setpoint - self.initial_search_value\n",
    "\n",
    "        output = self.disturbance_magnitude * np.sin(self.wt) + setpoint\n",
    "\n",
    "        # perturbation = self.disturbance_magnitude * np.sin(self.wt) \n",
    "\n",
    "        # update wt\n",
    "        self.wt += self.disturbance_frequency * self.dt\n",
    "        if self.wt > 2 * np.pi:\n",
    "            self.wt -= 2 * np.pi\n",
    "\n",
    "        return (\n",
    "            output,\n",
    "            high_pass_output,\n",
    "            low_pass_output,\n",
    "            gradient_mag,\n",
    "            low_pass_output,\n",
    "            setpoint,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e1ffd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtremumSeekingController(Callback):\n",
    "    \"\"\"\n",
    "    Implements an Extremum Seeking Controller to optimize a performance metric by\n",
    "    periodically adjusting the desired SND.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        control_group: str,\n",
    "        initial_snd: float,\n",
    "        \n",
    "        # ESC parameters\n",
    "        dither_magnitude: float, # Renamed from dither_amplitude for clarity\n",
    "        dither_frequency_rad_s: float, # Explicitly state units\n",
    "        integral_gain: float,\n",
    "        high_pass_cutoff_rad_s: float,\n",
    "        low_pass_cutoff_rad_s: float,\n",
    "        use_adapter: bool = True,\n",
    "        sampling_period: float = 1.0\n",
    "        ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.control_group = control_group\n",
    "        \n",
    "        self.initial_snd = initial_snd\n",
    "\n",
    "        self.esc_params = {\n",
    "            \"sampling_period\": sampling_period,\n",
    "            \"disturbance_frequency\": dither_frequency_rad_s,\n",
    "            \"disturbance_magnitude\": dither_magnitude,\n",
    "            \"integrator_gain\": integral_gain,\n",
    "            \"initial_search_value\": initial_snd,\n",
    "            \"high_pass_cutoff_frequency\": high_pass_cutoff_rad_s,\n",
    "            \"low_pass_cutoff_frequency\": low_pass_cutoff_rad_s,\n",
    "            \"use_adapter\": use_adapter,\n",
    "        }\n",
    "        # Controller state variables\n",
    "        self.model = None\n",
    "        self.controller = None\n",
    "\n",
    "    def on_setup(self):\n",
    "        \"\"\"Initializes the controller and logs hyperparameters.\"\"\"\n",
    "        hparams = {\n",
    "            # \"controller_type\": \"ExtremumSeeking_v2\",\n",
    "            \"control_group\": self.control_group,\n",
    "            **self.esc_params\n",
    "        }\n",
    "        self.experiment.logger.log_hparams(**hparams)\n",
    "\n",
    "        if self.control_group not in self.experiment.group_policies:\n",
    "            print(f\"\\nWARNING: Controller group '{self.control_group}' not found. Disabling controller.\\n\")\n",
    "            return\n",
    "\n",
    "        policy = self.experiment.group_policies[self.control_group]\n",
    "        self.model = get_het_model(policy)\n",
    "\n",
    "        if isinstance(self.model, HetControlMlpEmpirical):\n",
    "            print(f\"\\n✅ SUCCESS: Extremum Seeking Controller initialized for group '{self.control_group}'.\")\n",
    "            self.controller = esc(**self.esc_params)\n",
    "            self.model.desired_snd[:] = float(self.initial_snd)\n",
    "        else:\n",
    "            print(f\"\\nWARNING: A compatible model was not found for group '{self.control_group}'. Disabling controller.\\n\")\n",
    "            self.model = None\n",
    "\n",
    "    def on_evaluation_end(self, rollouts: List[TensorDictBase]):\n",
    "        if self.model is None or self.controller is None:\n",
    "            return\n",
    "        logs_to_push = {}\n",
    "        \n",
    "        # 1. Collect rewards + compute actual diversity for logging\n",
    "        episode_rewards = []\n",
    "        with torch.no_grad():\n",
    "            for r in rollouts:\n",
    "                reward_key = ('next', self.control_group, 'reward')\n",
    "                total_reward = r.get(reward_key).sum().item() if reward_key in r.keys(include_nested=True) else 0\n",
    "                episode_rewards.append(total_reward)\n",
    "\n",
    "        if not episode_rewards:\n",
    "            print(\"\\nWARNING: No episode rewards found. Cannot update controller.\\n\")\n",
    "            self.experiment.logger.log(logs_to_push, step=self.experiment.n_iters_performed)\n",
    "            return\n",
    "\n",
    "        reward_mean = np.mean(episode_rewards)\n",
    "        cost = -reward_mean  # Assuming we want to maximize reward, so cost is negative reward\n",
    "        \n",
    "        # 2. Call the core ES function\n",
    "        (\n",
    "            uk, \n",
    "            hpf_out, \n",
    "            lpf_out, \n",
    "            m2_sqrt, \n",
    "            gradient, \n",
    "            setpoint\n",
    "        ) = self.controller.update(cost)\n",
    "        \n",
    "        # 3. Update diversity parameter\n",
    "        previous_snd = self.model.desired_snd.item()\n",
    "        self.model.desired_snd[:] = torch.clamp(torch.tensor(uk), min=0.0)\n",
    "\n",
    "        print(f\"[ESC] Updated SND: {self.model.desired_snd.item()} \"\n",
    "              f\"(Reward: {reward_mean:.3f}, Update Step: {uk - previous_snd:.4f})\")\n",
    "\n",
    "        # 4. Logging\n",
    "        logs_to_push.update({\n",
    "            \"esc/mean_reward\": reward_mean,\n",
    "            \"esc/cost\": cost,\n",
    "            \"esc/diversity_output\": uk,\n",
    "            \"esc/diversity_setpoint\": setpoint,\n",
    "            \"esc/gradient_estimate\": gradient,\n",
    "            \"esc/hpf_output\": hpf_out,\n",
    "            \"esc/lpf_output\": lpf_out,\n",
    "            \"esc/m2_sqrt\": m2_sqrt,\n",
    "            \"esc/update_step\": uk - previous_snd\n",
    "        })\n",
    "        self.experiment.logger.log(logs_to_push, step=self.experiment.n_iters_performed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e30767",
   "metadata": {},
   "source": [
    "## Env Setup\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a397e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. EXPERIMENT LOGIC\n",
    "\n",
    "def setup(task_name):\n",
    "    benchmarl.models.model_config_registry.update(\n",
    "        {\n",
    "            \"hetcontrolmlpempirical\": HetControlMlpEmpiricalConfig,\n",
    "        }\n",
    "    )\n",
    "    if task_name == \"vmas/navigation\":\n",
    "        # Set the render callback for the navigation case study\n",
    "        VmasTask.render_callback = render_callback\n",
    "\n",
    "def get_experiment(cfg: DictConfig) -> Experiment:\n",
    "    hydra_choices = HydraConfig.get().runtime.choices\n",
    "    task_name = hydra_choices.task\n",
    "    algorithm_name = hydra_choices.algorithm\n",
    "\n",
    "    setup(task_name)\n",
    "\n",
    "    print(f\"\\nAlgorithm: {algorithm_name}, Task: {task_name}\")\n",
    "    # print(\"\\nLoaded config:\\n\") # Optional: Commented out to reduce clutter\n",
    "    # print(OmegaConf.to_yaml(cfg))\n",
    "\n",
    "    algorithm_config = load_algorithm_config_from_hydra(cfg.algorithm)\n",
    "    experiment_config = load_experiment_config_from_hydra(cfg.experiment)\n",
    "    task_config = load_task_config_from_hydra(cfg.task, task_name)\n",
    "    critic_model_config = load_model_config_from_hydra(cfg.critic_model)\n",
    "    model_config = load_model_config_from_hydra(cfg.model)\n",
    "\n",
    "    if isinstance(algorithm_config, (MappoConfig, IppoConfig, MasacConfig, IsacConfig)):\n",
    "        model_config.probabilistic = True\n",
    "        model_config.scale_mapping = algorithm_config.scale_mapping\n",
    "        algorithm_config.scale_mapping = (\n",
    "            \"relu\"  # The scaling of std_dev will be done in the model\n",
    "        )\n",
    "    else:\n",
    "        model_config.probabilistic = False\n",
    "\n",
    "    experiment = Experiment(\n",
    "        task=task_config,\n",
    "        algorithm_config=algorithm_config,\n",
    "        model_config=model_config,\n",
    "        critic_model_config=critic_model_config,\n",
    "        seed=cfg.seed,\n",
    "        config=experiment_config,\n",
    "        callbacks=[\n",
    "            SndCallback(),\n",
    "            ExtremumSeekingController(\n",
    "                        control_group=\"agents\",\n",
    "                        initial_snd=0.3,\n",
    "                        dither_magnitude=0.2,\n",
    "                        dither_frequency_rad_s=1.0,\n",
    "                        integral_gain=-0.01,\n",
    "                        high_pass_cutoff_rad_s=1.0,\n",
    "                        low_pass_cutoff_rad_s=1.0,\n",
    "                        sampling_period=1.0\n",
    "            ),\n",
    "            SNDVisualizerCallback(),\n",
    "            # TrajectorySNDLoggerCallback(control_group=\"agents\"),\n",
    "            NormLoggerCallback(),\n",
    "            ActionSpaceLoss(\n",
    "                use_action_loss=cfg.use_action_loss, action_loss_lr=cfg.action_loss_lr\n",
    "            ),\n",
    "        ]\n",
    "        + (\n",
    "            [\n",
    "                TagCurriculum(\n",
    "                    cfg.simple_tag_freeze_policy_after_frames,\n",
    "                    cfg.simple_tag_freeze_policy,\n",
    "                )\n",
    "            ]\n",
    "            if task_name == \"vmas/simple_tag\"\n",
    "            else []\n",
    "        ),\n",
    "    )\n",
    "    return experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de2e613",
   "metadata": {},
   "source": [
    "## Runner Code\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40d0405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config loaded from: /home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\n",
      "Running with SND: 1.0\n",
      "\n",
      "Algorithm: ippo, Task: vmas/navigation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msvarp\u001b[0m (\u001b[33msvarp-university-of-massachusetts-lowell\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/ippo_navigation_hetcontrolmlpempirical__0ea2f640_25_11_29-01_51_44/wandb/run-20251129_015148-ippo_navigation_hetcontrolmlpempirical__0ea2f640_25_11_29-01_51_44</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__0ea2f640_25_11_29-01_51_44' target=\"_blank\">ippo_navigation_hetcontrolmlpempirical__0ea2f640_25_11_29-01_51_44</a></strong> to <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__0ea2f640_25_11_29-01_51_44' target=\"_blank\">https://wandb.ai/svarp-university-of-massachusetts-lowell/benchmarl/runs/ippo_navigation_hetcontrolmlpempirical__0ea2f640_25_11_29-01_51_44</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/nn/functional.py:1956: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Experiment was closed gracefully\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Problem finishing run\n",
      "Error executing job with overrides: ['model.desired_snd=1.0', 'experiment.max_n_frames=6000000', 'experiment.checkpoint_interval=600000', 'experiment.save_folder=/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment finished successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/experiment.py\", line 519, in run\n",
      "    self._collection_loop()\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/experiment.py\", line 567, in _collection_loop\n",
      "    training_tds.append(self._optimizer_loop(group))\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/experiment.py\", line 658, in _optimizer_loop\n",
      "    optimizer.step()\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 140, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 23, in _use_grad\n",
      "    ret = func(self, *args, **kwargs)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/optim/adam.py\", line 234, in step\n",
      "    adam(params_with_grad,\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/optim/adam.py\", line 300, in adam\n",
      "    func(params,\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/torch/optim/adam.py\", line 363, in _single_tensor_adam\n",
      "    exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_2185079/2615263703.py\", line 34, in hydra_experiment\n",
      "    experiment.run()\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/experiment.py\", line 522, in run\n",
      "    self.close()\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/experiment.py\", line 629, in close\n",
      "    self.logger.finish()\n",
      "  File \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/BenchMARL/benchmarl/experiment/logger.py\", line 257, in finish\n",
      "    wandb.finish()\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 4105, in finish\n",
      "    wandb.run.finish(exit_code=exit_code, quiet=quiet)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 399, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 444, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2263, in finish\n",
      "    return self._finish(exit_code)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 399, in wrapper\n",
      "    return func(self, *args, **kwargs)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2291, in _finish\n",
      "    self._atexit_cleanup(exit_code=exit_code)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2486, in _atexit_cleanup\n",
      "    self._on_finish()\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/wandb_run.py\", line 2740, in _on_finish\n",
      "    wait_with_progress(\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/mailbox/wait_with_progress.py\", line 23, in wait_with_progress\n",
      "    return wait_all_with_progress(\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/mailbox/wait_with_progress.py\", line 77, in wait_all_with_progress\n",
      "    return asyncer.run(progress_loop_with_timeout)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/lib/asyncio_manager.py\", line 136, in run\n",
      "    return future.result()\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/concurrent/futures/_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/concurrent/futures/_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/lib/asyncio_manager.py\", line 219, in _wrap\n",
      "    return await fn()\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/mailbox/wait_with_progress.py\", line 72, in progress_loop_with_timeout\n",
      "    return await _wait_handles_async(\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/mailbox/wait_with_progress.py\", line 97, in _wait_handles_async\n",
      "    task_group.start_soon(wait_single(index))\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/contextlib.py\", line 188, in __aexit__\n",
      "    await self.gen.__anext__()\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/lib/asyncio_compat.py\", line 240, in open_task_group\n",
      "    await task_group._wait_all(race=race, timeout=exit_timeout)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/lib/asyncio_compat.py\", line 180, in _wait_all\n",
      "    raise exc\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/mailbox/wait_with_progress.py\", line 93, in wait_single\n",
      "    results[index] = await handle.wait_async(timeout=timeout)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/mailbox/mailbox_handle.py\", line 133, in wait_async\n",
      "    response = await self._handle.wait_async(timeout=timeout)\n",
      "  File \"/home/grad/doc/2027/spatel2/miniconda3/envs/ad2c/lib/python3.9/site-packages/wandb/sdk/mailbox/response_handle.py\", line 99, in wait_async\n",
      "    raise HandleAbandonedError()\n",
      "wandb.sdk.mailbox.mailbox_handle.HandleAbandonedError\n",
      "\n",
      "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n"
     ]
    }
   ],
   "source": [
    "ABS_CONFIG_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/AD2C/ControllingBehavioralDiversity/het_control/conf\"\n",
    "CONFIG_NAME = \"navigation_ippo\"  # Make sure 'navigation_ippo.yaml' exists in the folder above!\n",
    "SAVE_PATH = \"/home/grad/doc/2027/spatel2/AD2C_testBed/model_checkpoints/navigation_ippo_esc/\"\n",
    "\n",
    "save_interval = 600000\n",
    "desired_snd = 1.0\n",
    "max_frame = 6000000\n",
    "\n",
    "if not os.path.exists(SAVE_PATH):\n",
    "    print(f\"Creating missing directory: {SAVE_PATH}\")\n",
    "    os.makedirs(SAVE_PATH, exist_ok=True)\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "\n",
    "sys.argv = [\n",
    "    \"dummy.py\",\n",
    "    f\"model.desired_snd={desired_snd}\",\n",
    "    f\"experiment.max_n_frames={max_frame}\",\n",
    "    f\"experiment.checkpoint_interval={save_interval}\",\n",
    "    f\"experiment.save_folder={SAVE_PATH}\",\n",
    "]\n",
    "\n",
    "# 3. Define the Hydra wrapper\n",
    "@hydra.main(version_base=None, config_path=ABS_CONFIG_PATH, config_name=CONFIG_NAME)\n",
    "def hydra_experiment(cfg: DictConfig) -> None:\n",
    "    print(f\"Config loaded from: {ABS_CONFIG_PATH}\")\n",
    "    if wandb.run is not None:\n",
    "        print(\"Finishing previous WandB run...\")\n",
    "        wandb.finish()\n",
    "    \n",
    "    print(f\"Running with SND: {cfg.model.desired_snd}\")\n",
    "    \n",
    "    experiment = get_experiment(cfg=cfg)\n",
    "    experiment.run()\n",
    "    wandb.finish()\n",
    "\n",
    "# 4. Execute safely\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        hydra_experiment()\n",
    "    except SystemExit:\n",
    "        print(\"Experiment finished successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1c6b51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad2c",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
